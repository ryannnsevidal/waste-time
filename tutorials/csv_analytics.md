# csv analytics guide

complete guide for understanding and analyzing the csv data generated by the waste time bot

## csv file overview

### automatic csv generation
the sophisticated engine automatically creates csv files every time it processes scammer input:
- files saved to `analytics_data/scammer_analysis_YYYYMMDD.csv`
- new file created each day
- all data automatically exported in real-time

### data privacy & security
- csv files are automatically gitignored
- data stays local on your machine
- never uploaded to github or shared externally
- safe to analyze without privacy concerns

## csv data structure

### column definitions

| column | type | description |
|--------|------|-------------|
| `timestamp` | datetime | when the response was generated |
| `scammer_input` | text | what the scammer said (truncated to 200 chars) |
| `strategy` | text | ai strategy chosen (confusion, payment_confusion, etc) |
| `response_preview` | text | preview of bot response (truncated to 100 chars) |
| `urgency_score` | integer | how urgent scammer sounds (0-20+) |
| `authority_score` | integer | authority claims detected (0-20+) |
| `payment_score` | integer | payment requests detected (0-20+) |
| `info_score` | integer | personal info requests (0-20+) |
| `frustration_score` | integer | scammer frustration level |
| `threat_score` | integer | legal threats detected |
| `caps_ratio` | float | percentage of CAPS in message |
| `exclamation_count` | integer | number of ! marks |
| `estimated_time_waste` | integer | predicted seconds of time wasted |
| `total_time_wasted` | integer | cumulative time wasted in conversation |
| `scammer_frustration` | float | overall frustration level |
| `is_high_urgency` | boolean | true if very urgent language detected |
| `is_authority_claim` | boolean | true if claims government/company authority |
| `is_payment_scam` | boolean | true if requesting payment |
| `is_info_phishing` | boolean | true if requesting personal info |
| `is_threatening` | boolean | true if making legal threats |

### example csv row
```csv
2025-07-20T19:36:39.026752,You need to buy gift cards NOW!,payment_confusion,How much gift can fit on such a small card?,4,0,8,0,0,0,0.129,1,120,120,0.558,False,False,True,False,False
```

## analyzing csv data

### basic analysis with command line

```bash
# view file structure
head -1 analytics_data/scammer_analysis_20250720.csv

# count total interactions
wc -l analytics_data/scammer_analysis_20250720.csv

# most common strategies
cut -d, -f3 analytics_data/scammer_analysis_20250720.csv | sort | uniq -c | sort -nr

# total time wasted
awk -F, '{sum += $13} END {print "Total time wasted:", sum, "seconds (" sum/60 " minutes)"}' analytics_data/scammer_analysis_20250720.csv

# high urgency scams
grep ",True," analytics_data/scammer_analysis_20250720.csv | wc -l

# payment scams detected
awk -F, '$18 == "True" {count++} END {print "Payment scams:", count}' analytics_data/scammer_analysis_20250720.csv
```

### python pandas analysis

```python
import pandas as pd
import matplotlib.pyplot as plt

# load csv data
df = pd.read_csv('analytics_data/scammer_analysis_20250720.csv')

# basic statistics
print("dataset overview:")
print(f"total interactions: {len(df)}")
print(f"total time wasted: {df['estimated_time_waste'].sum()} seconds")
print(f"average time per interaction: {df['estimated_time_waste'].mean():.1f} seconds")

# strategy effectiveness
strategy_stats = df.groupby('strategy').agg({
    'estimated_time_waste': ['mean', 'sum', 'count'],
    'scammer_frustration': 'mean'
}).round(2)

print("\nstrategy effectiveness:")
print(strategy_stats)

# scam type distribution
scam_types = {
    'payment_scams': df['is_payment_scam'].sum(),
    'authority_claims': df['is_authority_claim'].sum(), 
    'info_phishing': df['is_info_phishing'].sum(),
    'high_urgency': df['is_high_urgency'].sum(),
    'threatening': df['is_threatening'].sum()
}

print("\nscam type detection:")
for scam_type, count in scam_types.items():
    percentage = (count / len(df)) * 100
    print(f"{scam_type}: {count} ({percentage:.1f}%)")
```

### advanced analytics

```python
import pandas as pd
import numpy as np

# load data
df = pd.read_csv('analytics_data/scammer_analysis_20250720.csv')

# time series analysis
df['timestamp'] = pd.to_datetime(df['timestamp'])
df['hour'] = df['timestamp'].dt.hour

hourly_stats = df.groupby('hour').agg({
    'estimated_time_waste': 'sum',
    'scammer_frustration': 'mean'
}).round(2)

print("hourly patterns:")
print(hourly_stats)

# correlation analysis
numeric_cols = ['urgency_score', 'authority_score', 'payment_score', 
               'estimated_time_waste', 'scammer_frustration']
correlation_matrix = df[numeric_cols].corr()

print("\ncorrelations:")
print(correlation_matrix)

# effectiveness scoring
df['effectiveness_score'] = (
    df['estimated_time_waste'] * 0.4 +
    df['scammer_frustration'] * 100 * 0.3 +
    df['urgency_score'] * 10 * 0.2 +
    df['caps_ratio'] * 100 * 0.1
)

top_effective = df.nlargest(5, 'effectiveness_score')[
    ['scammer_input', 'strategy', 'effectiveness_score', 'estimated_time_waste']
]

print("\nmost effective responses:")
print(top_effective)
```

## visualization examples

### plotting with matplotlib

```python
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv('analytics_data/scammer_analysis_20250720.csv')

# strategy usage pie chart
strategy_counts = df['strategy'].value_counts()
plt.figure(figsize=(10, 6))
plt.pie(strategy_counts.values, labels=strategy_counts.index, autopct='%1.1f%%')
plt.title('AI Strategy Usage Distribution')
plt.show()

# time waste by strategy
plt.figure(figsize=(12, 6))
strategy_time = df.groupby('strategy')['estimated_time_waste'].sum().sort_values(ascending=False)
plt.bar(strategy_time.index, strategy_time.values)
plt.title('Total Time Wasted by Strategy')
plt.xlabel('Strategy')
plt.ylabel('Time Wasted (seconds)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# scammer frustration over time
plt.figure(figsize=(12, 6))
df['timestamp'] = pd.to_datetime(df['timestamp'])
plt.plot(df['timestamp'], df['scammer_frustration'].cumsum())
plt.title('Cumulative Scammer Frustration Over Time')
plt.xlabel('Time')
plt.ylabel('Cumulative Frustration')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```

### seaborn advanced plots

```python
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv('analytics_data/scammer_analysis_20250720.csv')

# heatmap of scam detection
scam_detection = df[['is_payment_scam', 'is_authority_claim', 'is_info_phishing', 'is_threatening']].astype(int)
plt.figure(figsize=(8, 6))
sns.heatmap(scam_detection.corr(), annot=True, cmap='coolwarm', center=0)
plt.title('Scam Type Detection Correlation')
plt.show()

# box plot of time waste by strategy
plt.figure(figsize=(14, 8))
sns.boxplot(data=df, x='strategy', y='estimated_time_waste')
plt.title('Time Waste Distribution by Strategy')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# scatter plot: urgency vs time waste
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='urgency_score', y='estimated_time_waste', 
                hue='strategy', alpha=0.7)
plt.title('Urgency Score vs Time Waste by Strategy')
plt.show()
```

## custom analytics functions

### effectiveness calculator

```python
def calculate_strategy_effectiveness(csv_file):
    """calculate comprehensive effectiveness scores for each strategy"""
    import pandas as pd
    
    df = pd.read_csv(csv_file)
    
    effectiveness = df.groupby('strategy').agg({
        'estimated_time_waste': ['mean', 'sum', 'count'],
        'scammer_frustration': 'mean',
        'urgency_score': 'mean',
        'caps_ratio': 'mean'
    }).round(2)
    
    # flatten column names
    effectiveness.columns = ['_'.join(col).strip() for col in effectiveness.columns]
    
    # calculate composite effectiveness score
    effectiveness['composite_score'] = (
        effectiveness['estimated_time_waste_mean'] * 0.4 +
        effectiveness['scammer_frustration_mean'] * 100 * 0.3 +
        effectiveness['urgency_score_mean'] * 5 * 0.2 +
        effectiveness['caps_ratio_mean'] * 100 * 0.1
    )
    
    return effectiveness.sort_values('composite_score', ascending=False)

# usage
results = calculate_strategy_effectiveness('analytics_data/scammer_analysis_20250720.csv')
print(results)
```

### scam pattern detector

```python
def detect_scam_patterns(csv_file):
    """identify common scammer patterns"""
    import pandas as pd
    
    df = pd.read_csv(csv_file)
    
    patterns = {}
    
    # high urgency + payment requests
    urgent_payment = df[(df['urgency_score'] >= 5) & (df['payment_score'] >= 5)]
    patterns['urgent_payment_scams'] = len(urgent_payment)
    
    # authority claims + threats
    authority_threats = df[(df['authority_score'] >= 5) & (df['threat_score'] >= 2)]
    patterns['authority_threat_scams'] = len(authority_threats)
    
    # info phishing with low urgency (patient scammers)
    patient_phishing = df[(df['info_score'] >= 3) & (df['urgency_score'] <= 2)]
    patterns['patient_info_gathering'] = len(patient_phishing)
    
    # frustrated scammers (high caps ratio)
    frustrated = df[df['caps_ratio'] > 0.3]
    patterns['frustrated_scammers'] = len(frustrated)
    
    return patterns

# usage
patterns = detect_scam_patterns('analytics_data/scammer_analysis_20250720.csv')
for pattern, count in patterns.items():
    print(f"{pattern}: {count} instances")
```

## reporting and dashboards

### automated daily report

```python
def generate_daily_report(csv_file):
    """generate automated daily summary report"""
    import pandas as pd
    from datetime import datetime
    
    df = pd.read_csv(csv_file)
    
    report = []
    report.append(f"📊 daily scammer analysis report - {datetime.now().strftime('%Y-%m-%d')}")
    report.append("=" * 60)
    report.append("")
    
    # basic stats
    total_interactions = len(df)
    total_time_wasted = df['estimated_time_waste'].sum()
    avg_frustration = df['scammer_frustration'].mean()
    
    report.append("🎯 key metrics:")
    report.append(f"   • total scammer interactions: {total_interactions}")
    report.append(f"   • total time wasted: {total_time_wasted:,.0f} seconds ({total_time_wasted/60:.1f} minutes)")
    report.append(f"   • average scammer frustration: {avg_frustration:.2f}/10")
    report.append("")
    
    # top strategies
    top_strategies = df['strategy'].value_counts().head(3)
    report.append("🏆 most used strategies:")
    for strategy, count in top_strategies.items():
        pct = (count / total_interactions) * 100
        report.append(f"   • {strategy}: {count} times ({pct:.1f}%)")
    report.append("")
    
    # scam detection
    scam_stats = {
        'payment scams': df['is_payment_scam'].sum(),
        'authority claims': df['is_authority_claim'].sum(),
        'info phishing': df['is_info_phishing'].sum(),
        'threats detected': df['is_threatening'].sum()
    }
    
    report.append("🚨 scam detection summary:")
    for scam_type, count in scam_stats.items():
        pct = (count / total_interactions) * 100
        report.append(f"   • {scam_type}: {count} ({pct:.1f}%)")
    
    return "\n".join(report)

# usage
report = generate_daily_report('analytics_data/scammer_analysis_20250720.csv')
print(report)

# save to file
with open(f'analytics_data/daily_report_{datetime.now().strftime("%Y%m%d")}.txt', 'w') as f:
    f.write(report)
```

## csv maintenance

### file management

```python
import os
import glob
from datetime import datetime, timedelta

def cleanup_old_csv_files(days_to_keep=30):
    """remove csv files older than specified days"""
    cutoff_date = datetime.now() - timedelta(days=days_to_keep)
    
    csv_files = glob.glob('analytics_data/scammer_analysis_*.csv')
    removed_count = 0
    
    for file_path in csv_files:
        file_date = datetime.fromtimestamp(os.path.getctime(file_path))
        if file_date < cutoff_date:
            os.remove(file_path)
            removed_count += 1
            print(f"removed old file: {file_path}")
    
    print(f"cleanup complete: {removed_count} files removed")

def merge_csv_files(output_file='analytics_data/merged_analysis.csv'):
    """merge multiple daily csv files into one"""
    import pandas as pd
    
    csv_files = glob.glob('analytics_data/scammer_analysis_*.csv')
    
    if not csv_files:
        print("no csv files found")
        return
    
    # read and combine all files
    dataframes = []
    for file in csv_files:
        df = pd.read_csv(file)
        df['source_file'] = os.path.basename(file)
        dataframes.append(df)
    
    merged_df = pd.concat(dataframes, ignore_index=True)
    merged_df.to_csv(output_file, index=False)
    
    print(f"merged {len(csv_files)} files into {output_file}")
    print(f"total records: {len(merged_df)}")

# usage
cleanup_old_csv_files(30)
merge_csv_files()
```

this guide covers everything you need to analyze the csv data generated by the waste time bot. the automatic logging captures detailed metrics about every scammer interaction, allowing for comprehensive analysis of ai effectiveness and scammer behavior patterns.
